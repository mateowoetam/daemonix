name: Build disk images

on:
  workflow_dispatch:
    inputs:
      upload-to-s3:
        description: "Upload to S3"
        required: false
        default: false
        type: boolean
      platform:
        description: "Target Platform"
        required: true
        default: "amd64"
        type: choice
        options:
          - amd64
          - arm64

  pull_request:
    branches: [main]
    paths:
      - 'disk_config/**'
      - '.github/workflows/build-disk.yml'

env:
  IMAGE_NAME: ${{ github.event.repository.name }}
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  DEFAULT_TAG: latest
  BIB_IMAGE: quay.io/centos-bootc/bootc-image-builder:latest

concurrency:
  group: ${{ github.workflow }}-${{ github.ref || github.run_id }}
  cancel-in-progress: true

jobs:
  build:
    name: Build disk images
    runs-on: ${{ github.event.inputs.platform == 'arm64' && 'ubuntu-24.04-arm' || 'ubuntu-24.04' }}

    strategy:
      fail-fast: false
      matrix:
        disk-type: [qcow2, anaconda-iso]
        # This handles both daemonix-base and daemonix-nvidia images
        image-variant: [base, nvidia]

    permissions:
      contents: read
      packages: write
      id-token: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Prepare environment
        shell: bash
        run: |
          echo "IMAGE_REGISTRY=${IMAGE_REGISTRY,,}" >> "$GITHUB_ENV"
          echo "IMAGE_NAME=${IMAGE_NAME,,}" >> "$GITHUB_ENV"
          echo "USER_UID=$(id -u)" >> "$GITHUB_ENV"
          echo "USER_GID=$(id -g)" >> "$GITHUB_ENV"
          # Define a fixed path for the auth file to ensure the builder finds it
          echo "REGISTRY_AUTH_FILE=${{ github.workspace }}/auth.json" >> "$GITHUB_ENV"

      - name: Maximize build space
        if: github.event.inputs.platform != 'arm64'
        uses: jlumbroso/free-disk-space@v1.3.1
        with:
          remove-codeql: true

      - name: Log into GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
          # This exports the login token to the file we defined in Prepare Environment
          logout: false

      - name: Build disk image (${{ matrix.image-variant }})
        id: build
        uses: osbuild/bootc-image-builder-action@main
        with:
          builder-image: ${{ env.BIB_IMAGE }}
          config-file: ${{ matrix.disk-type == 'anaconda-iso' && './disk_config/iso.toml' || './disk_config/disk.toml' }}
          image: ${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}-${{ matrix.image-variant }}:${{ env.DEFAULT_TAG }}
          chown: ${{ env.USER_UID }}:${{ env.USER_GID }}
          types: ${{ matrix.disk-type }}
          # Use the environment variable we defined to avoid "Forbidden" errors
          additional-args: |
            --authfile ${{ env.REGISTRY_AUTH_FILE }}

      - name: Install Cosign
        if: github.event_name != 'pull_request'
        uses: sigstore/cosign-installer@v3.8.0

      - name: Sign source container image
        if: github.event_name != 'pull_request'
        run: |
          IMAGE_REF="${{ env.IMAGE_REGISTRY }}/${{ env.IMAGE_NAME }}-${{ matrix.image-variant }}:${{ env.DEFAULT_TAG }}"
          cosign sign -y --key env://COSIGN_PRIVATE_KEY "$IMAGE_REF"
        env:
          COSIGN_PRIVATE_KEY: ${{ secrets.SIGNING_SECRET }}
          COSIGN_PASSWORD: ${{ secrets.COSIGN_PASSWORD }}

      - name: Upload disk images
        if: github.event.inputs.upload-to-s3 != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.image-variant }}-${{ matrix.disk-type }}-${{ github.event.inputs.platform }}
          path: ${{ steps.build.outputs.output-directory }}
          retention-days: 5

      - name: Upload to S3
        if: github.event.inputs.upload-to-s3 == 'true' && github.event_name != 'pull_request'
        shell: bash
        env:
          RCLONE_CONFIG_S3_TYPE: s3
          RCLONE_CONFIG_S3_PROVIDER: ${{ secrets.S3_PROVIDER }}
          RCLONE_CONFIG_S3_ACCESS_KEY_ID: ${{ secrets.S3_ACCESS_KEY_ID }}
          RCLONE_CONFIG_S3_SECRET_ACCESS_KEY: ${{ secrets.S3_SECRET_ACCESS_KEY }}
          RCLONE_CONFIG_S3_REGION: ${{ secrets.S3_REGION }}
          RCLONE_CONFIG_S3_ENDPOINT: ${{ secrets.S3_ENDPOINT }}
        run: |
          sudo apt-get update && sudo apt-get install -y rclone
          rclone copy "${{ steps.build.outputs.output-directory }}" \
            "S3:${{ secrets.S3_BUCKET_NAME }}/${{ matrix.image-variant }}/${{ github.run_id }}"
